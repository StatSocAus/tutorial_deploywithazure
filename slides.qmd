---
title: "Get your model into prod"
subtitle: "Deploying your modelling code into production with Microsoft Azure"
author: "Dean Marchiori"
institute: "Wave Data Labs"
format: 
  revealjs:
    theme: [simple]
    incremental: true
    slide-number: true
    show-slide-number: all
    footer: "[https://deanmarchiori.github.io/deploywithazure](https://deanmarchiori.github.io/deploywithazure)"
---

```{r}
#| include: false
library(icons)

icons_fa <- icons::fontawesome
icon_link <- icon_style(icons_fa$solid$link, fill = "#2A6496", float = "left")
icon_github <- icon_style(icons_fa$brands$github, fill = "#2A6496", float = "left")
icon_plane <- icon_style(icons_fa$solid$`paper-plane`, fill = "#2A6496", float = "left")

```

## Go from this... 

{{< video img/model.webm width="900" height="600" >}}

## To this... 

![](img/tothis.png)

# Part 1: Overview of Machine Learning Operations (MLOps)

## What is MLOps?    

![Source: [Kreuzberger (2023)](https://doi.org/10.1109/ACCESS.2023.3262138)](img/ven1.gif)  

## What is MLOps?     

:::: {.columns}

::: {.column width="60%"}
- CI/CD Automation  
- Workflow Orchestration  
- Reproducibility  
- Versioning of data, model, code  
- ML metadata tracking  
- Monitoring & Feedback
:::

::: {.column width="40%"}
![](img/ven1.gif)
:::

::::

Source: [Kreuzberger (2023)](https://doi.org/10.1109/ACCESS.2023.3262138)


## Who is MLOps?  

![Source: [Kreuzberger (2023)](https://doi.org/10.1109/ACCESS.2023.3262138)](img/ven2.gif)  


## Who is MLOps?    

::: {layout-ncol=2}
![](img/ven2.gif)

![](img/chan.jpeg)
:::

## Experimentation vs Productionisation  (Inner Loop vs Outer Loop)  

:::: {.columns}

::: {.column width="60%"}
- Business Understanding  
- Data Understanding  
- Data Preparation  
- Modelling  
- Evaluation  
- Deployment  

Source: [CRISP-DM](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)

:::

::: {.column width="40%"}
![Kenneth Jensen, [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0), via Wikimedia Commons](img/crispdm.png)
:::

::::

--- 

- **Outer Loop**  
- Infrastructure Deployment
  - **Inner Loop**    

    :::{.nonincremental}
      - Business Understanding  
      - Data Understanding  
      - Data Preparation  
      - Modelling  
      - Evaluation   
    :::  
  
- Model Registration and Deployment  
- Monitoring  

## Reference Architecture  

![](img/arch.png)  


## Deployment patterns

```{mermaid}
graph TD;
    MLArchitecture-->Classic;
    MLArchitecture-->ComputerVision;
    MLArchitecture-->NLP;
    Infra-Deployment-->Bicep;
    Infra-Deployment-->Terraform;
    Infra-Deployment-->CLI;
```

<br> 
<br> 

```{mermaid}
graph TD;
    Orchestration-->AzureDevOps;
    Orchestration-->Github;
    MlOpsCode-->Python-SDK;
    MlOpsCode-->Azure-CLI-v2;
```

## Azure ML Studio Tour  

![](img/azureml.png)


# Part 2: Converting development code into production quality code   

## Case Study:  Predict NYC Taxi Fares      

Not really important, just a quick example.  

:::: {.columns}

::: {.column width="50%"}

```{python, python.reticulate = FALSE}
#| eval: false
#| echo: true
RandomForestRegressor(n_estimators = 500,
                      bootstrap = 1,
                      max_depth = 10,
                      max_features = 1.0,
                      min_samples_leaf = 4,
                      min_samples_split = 5,
                      random_state=0)
```

:::

::: {.column width="50%"}
```
#| eval: false
#| echo: true

TARGET_COL = "cost"

NUMERIC_COLS = [
    "distance",
    "dropoff_latitude",
    "dropoff_longitude",
    "passengers",
    "pickup_latitude",
    "pickup_longitude",
    "pickup_weekday",
    "pickup_month",
    "pickup_monthday",
    "pickup_hour",
    "pickup_minute",
    "pickup_second",
    "dropoff_weekday",
    "dropoff_month",
    "dropoff_monthday",
    "dropoff_hour",
    "dropoff_minute",
    "dropoff_second",
]

CAT_NOM_COLS = [
    "store_forward",
    "vendor",
]

```

:::

::::

## Review experimentation code   

```{mermaid}
graph TB
    subgraph id1 [Monolithic Notebook]
    a1[Load Dependencies]-->a2[Data Prep]-->a3[Test/Train Split]-->a4[Train Model]-->a5[Evaluate Model]-->a6[Diagnostics]
    end
    a7[(Data)]-->a2
    style id1 fill:lightblue;
```

## Split into scripts

```{mermaid}
graph LR
  a1[[Data Prep]]-->a2[[Model Training]]-->a3[[Evaluation]]-->a4[[Unit Tests]]
```

- Read in required inputs  
- Export object for next step  
- Parameterise scripts with [`argparse`](https://pypi.org/project/argparse/)  
- Add logging using [`mlflow`](https://mlflow.org/)  
- Bundling code as functions  


## MLOps additions

```{mermaid}
graph TB
  b1[[Infrastructure Deploy]]
  a1[[Data Prep]]-->a2[[Model Training]]-->a3[[Evaluation]]-->a4[[Unit Tests]]
  e1[[Deploy REST API Endpoint]]
  style b1 fill:red
  style e1 fill:red
```

## Convert to 'pipelines'  

```{mermaid}
flowchart LR
  subgraph p1[Infra Deploy Pipeline]
  b1[[Infrastructure Deploy]]
  end
  subgraph p2[Model Training Pipeline]
  a1[[Data Prep]]-->a2[[Model Training]]-->a3[[Evaluation]]-->a4[[Unit Tests]]
  end
  subgraph p3[Endpoint Deployment Pipeline]
  e1[[Deploy REST API Endpoint]]
  end
  p1 --> p2
  p2-->p3
  style p1 fill:lightblue;
  style p2 fill:lightblue;
  style p3 fill:lightblue;
```

## More detailed pipeline  

```{mermaid}
flowchart LR
  s1[[config.yml]]-->b2
  subgraph p1[Infra Deploy Pipeline]
    direction TB
    b1[[install az cli]]-->b2[[create resource group]]-->b3[[create workspace]]-->b4[[create compute]]
  end
  a7[[environment.yaml]]-->a6
  a9[(Data)]-->a8
  subgraph p2[Model Training Pipeline]
    direction TB
    a6[[register environment]]-->a8[[register data]]-->a1[[Data Prep]]-->a2[[Model Training]]-->a3[[Evaluation]]-->a4[[Register Model]]
  end
  subgraph p3[Endpoint Deployment Pipeline]
    direction TB
    e1[[Create REST Online endpoint]]-->e2[[Deploy Model to enpoint]]-->e3[[test endpoint]]
  end
  p1 --> p2
  p2-->p3
  style p1 fill:lightblue;
  style p2 fill:lightblue;
  style p3 fill:lightblue;
```

## Result? A sea of YAML files

![](img/sea.jpg)

# Part 3: Deploying MLOps pipelines  

## Setup    

:::{.nonincremental}
1. Create service principal in Azure Portal   
2. Create new project in DevOps  
3. Configure authentication with Azure + Security  
4. Clone repo from MLOps template  
5. Set up pipelines from the `.yml` files  
:::

Detailed Instructions at:  

[MLOps Quickstart](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-mlops-azureml)  

More bespoke instructions at:   
[Azure MLOps (v2) Solution Accelerator](https://github.com/Azure/mlops-v2)


## Infrastructure as Code deployment    

:::: {.columns}

::: {.column width="60%"}
1. Create the resource group   
2. Create the Azure ML workspace  
3. Connect to the Azure ML workspace  
4. Create the compute target  

:::

::: {.column width="40%"}
![](img/pipeline1.png)
:::

::::

## Model training    

:::: {.columns}

::: {.column width="60%"}
1. Connect to the Azure ML workspace  
2. Register the environment  
3. Create the compute target  
4. Register data  
5. Run the ML Pipeline

:::

::: {.column width="40%"}
![](img/pipeline2.png)
:::

::::

## Endpoint deployment and test    

:::: {.columns}

::: {.column width="60%"}
1. Connect to the Azure ML workspace    
2. Create the online endpoint   
3. Create the online deployment 
4. Allocate traffic to the online deployment 
5. Test the online deployment   

:::

::: {.column width="40%"}
![](img/pipeline3.png)
:::

::::

## Real World Considerations

  - Usage / monitoring  
  - Security  
  - Prod vs Dev  
  - Unit Tests
  - Model performance promotion  
  - Monitoring 
  - CI/CD  


## Learning more

<br>

For all resources visit: [https://deanmarchiori.github.io/deploywithazure](https://deanmarchiori.github.io/deploywithazure)  

<br>

### Contact Info 

`r icon_link`   [deanmarchiori.com](deanmarchiori.com)

`r icon_github`   deanmarchiori  

`r icon_plane`   dean@wavedatalabs.com.au

